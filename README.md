# ğŸš€ Agentic RAG System with CrewAI

A **production-grade Retrieval-Augmented Generation (RAG)** system built with multi-agent orchestration using **CrewAI**, **OpenAI GPT-4**, and **Milvus Cloud**.

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-orange.svg)
![Milvus](https://img.shields.io/badge/Milvus-Cloud-purple.svg)
![CrewAI](https://img.shields.io/badge/CrewAI-Latest-red.svg)

## âœ¨ Key Features

### ğŸ¤– Multi-Agent Architecture (CrewAI)

| Agent          | Role                  | Capabilities                                                       |
| -------------- | --------------------- | ------------------------------------------------------------------ |
| **Supervisor** | Query Planning        | Deep intent analysis, multi-step decomposition, execution planning |
| **Retriever**  | Information Retrieval | Multi-modal search, cross-reference expansion, source attribution  |
| **Generator**  | Response Synthesis    | Context-aware generation, citation integration, structured output  |
| **Feedback**   | Quality Assurance     | Validation, scoring, improvement suggestions                       |

### ğŸ“„ Advanced Document Processing

- **Multi-format Support**: PDF, DOCX, XLSX, PPTX, HTML, Markdown, images
- **EasyOCR**: Multilingual OCR (English, Hindi, German, French, Spanish+)
- **spaCy NLP**: Entity extraction, keyword detection, text cleanup
- **Cross-Reference Linking**: Automatic linking between text â†” tables â†” images

### ğŸ” State-of-the-Art Retrieval

| Feature                      | Description                                   |
| ---------------------------- | --------------------------------------------- |
| **HNSW Index**               | High-performance vector search (Milvus Cloud) |
| **RRF Fusion**               | Combines dense + BM25 for hybrid search       |
| **Cross-Encoder Re-ranking** | Improved relevance with ms-marco model        |
| **MMR Diversity**            | Prevents redundant results                    |
| **Multi-Query Retrieval**    | Query variations for better coverage          |

### ğŸ’¾ Production Infrastructure

- **LLM**: OpenAI GPT-4o-mini (with function calling)
- **Embeddings**: OpenAI text-embedding-3-small (1536 dimensions)
- **Vector Store**: Milvus Cloud (Zilliz) with HNSW indexing
- **Streaming**: Real-time response generation

## ğŸ“ Project Structure

```
Agentic_RAG-Crewai/
â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”œâ”€â”€ main.py              # App entry point
â”‚   â”œâ”€â”€ models/              # Pydantic models
â”‚   â””â”€â”€ routes/              # API routes
â”œâ”€â”€ agents/                   # CrewAI agents
â”‚   â”œâ”€â”€ supervisor_agent.py  # Query analysis & planning
â”‚   â”œâ”€â”€ retriever_agent.py   # Multi-modal retrieval
â”‚   â”œâ”€â”€ generator_agent.py   # Response synthesis
â”‚   â”œâ”€â”€ feedback_agent.py    # Quality validation
â”‚   â””â”€â”€ tools/               # Agent tools
â”‚       â”œâ”€â”€ milvus_tool.py   # Milvus search tool
â”‚       â””â”€â”€ online_search_tool.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml          # Main configuration
â”‚   â”œâ”€â”€ crew_config.yaml     # Agent configurations
â”‚   â””â”€â”€ .env                 # Environment variables
â”œâ”€â”€ data_pipeline/
â”‚   â”œâ”€â”€ chunker.py           # Cross-reference chunking
â”‚   â”œâ”€â”€ ocr_processor.py     # EasyOCR + spaCy
â”‚   â”œâ”€â”€ file_loader.py       # Multi-format loader
â”‚   â””â”€â”€ ingestion_pipeline.py
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ openai_embedder.py   # OpenAI embeddings
â”‚   â””â”€â”€ milvus_store.py      # Milvus Cloud store
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ openai_client.py     # OpenAI GPT client
â”‚   â””â”€â”€ base_llm.py
â”œâ”€â”€ retriever/
â”‚   â””â”€â”€ advanced_retriever.py # RRF, re-ranking, MMR
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ crew_manager.py      # Agent orchestration
â”‚   â”œâ”€â”€ memory_store.py
â”‚   â””â”€â”€ trace_logger.py
â”œâ”€â”€ run.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- OpenAI API Key
- Milvus Cloud Account (Zilliz Cloud)

### 1. Clone and Setup

```bash
git clone https://github.com/yourusername/Agentic_RAG-Crewai.git
cd Agentic_RAG-Crewai

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm
```

### 2. Configure Environment

```bash
# Copy environment template
cp config/.env.example config/.env
```

Edit `config/.env`:

```env
# Required: OpenAI
OPENAI_API_KEY=sk-your-openai-key-here

# Required: Milvus Cloud (Zilliz)
MILVUS_URI=https://your-cluster.api.gcp-us-west1.zillizcloud.com
MILVUS_TOKEN=your-milvus-api-token

# Optional: Web Search
SERPER_API_KEY=
TAVILY_API_KEY=
```

### 3. Get Milvus Cloud Credentials

1. Go to [cloud.zilliz.com](https://cloud.zilliz.com)
2. Create a free cluster
3. Get your **Public Endpoint** (URI)
4. Create an **API Key** (Token)
5. Add to your `.env` file

### 4. Run the Application

```bash
python run.py
```

### 5. Access the API

```
API: http://localhost:8000
Docs: http://localhost:8000/docs
Health: http://localhost:8000/health
```

## ğŸ“¡ API Endpoints

### Query Processing

```bash
# Multi-agent query processing
POST /api/v1/agent_query
Content-Type: application/json

{
  "query": "What are the key findings in the Q3 report?",
  "use_web_search": false
}
```

### Document Ingestion

```bash
# Ingest from directory
POST /api/v1/ingest
{
  "directory": "./data/raw"
}

# Upload file
POST /api/v1/ingest/upload
Content-Type: multipart/form-data
file: <your-document>
```

### System Health

```bash
GET /health

# Response
{
  "status": "healthy",
  "version": "2.0.0",
  "components": {
    "llm": {"status": "healthy", "provider": "openai"},
    "vector_store": {
      "status": "healthy",
      "provider": "milvus_cloud",
      "index_type": "HNSW",
      "document_count": 1250
    }
  }
}
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Layer                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CrewAI Orchestrator                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Supervisorâ”‚â”€â”€â”‚ Retriever â”‚â”€â”€â”‚ Generator â”‚â”€â”€â”‚ Feedback  â”‚ â”‚
â”‚  â”‚   Agent   â”‚  â”‚   Agent   â”‚  â”‚   Agent   â”‚  â”‚   Agent   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI GPT-4   â”‚  â”‚  Milvus Cloud   â”‚  â”‚   Web Search    â”‚
â”‚  (LLM Engine)   â”‚  â”‚  (HNSW Index)   â”‚  â”‚   (Optional)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Retrieval Pipeline

```
Query â†’ Multi-Query Generation
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â–¼               â–¼
Dense Search    BM25 Search
(HNSW)          (Keywords)
    â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
      RRF Fusion (k=60)
            â”‚
            â–¼
   Cross-Encoder Re-ranking
            â”‚
            â–¼
    MMR Diversity (Î»=0.5)
            â”‚
            â–¼
      Final Results
```

## ğŸ“Š HNSW Index Configuration

The system uses HNSW (Hierarchical Navigable Small World) indexing for optimal search performance:

| Parameter        | Value  | Description                                    |
| ---------------- | ------ | ---------------------------------------------- |
| `M`              | 32     | Graph connectivity (higher = better recall)    |
| `efConstruction` | 360    | Build-time quality (higher = better index)     |
| `efSearch`       | 128    | Search-time quality (higher = better accuracy) |
| `metric_type`    | COSINE | Similarity metric for normalized embeddings    |

## ğŸ³ Docker Deployment

```bash
# Build and run
docker-compose up --build -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

## ğŸ”§ Configuration

### Main Configuration (`config/config.yaml`)

```yaml
llm:
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.2

embedding:
  provider: "openai"
  model: "text-embedding-3-small"
  dimension: 1536

vector_db:
  provider: "milvus_cloud"
  index_type: "HNSW"
  hnsw:
    m: 32
    ef_construction: 360
    ef_search: 128

retrieval:
  fusion_method: "rrf"
  enable_rerank: true
  enable_diversity: true
  enable_bm25: true

chunking:
  strategy: "semantic"
  enable_cross_reference: true
  enable_hierarchy: true
```

## ğŸ“ˆ Performance Tips

1. **Increase HNSW M** for better recall (costs more memory)
2. **Increase efSearch** for better accuracy (costs query time)
3. **Use text-embedding-3-large** for higher quality embeddings
4. **Enable GPU** for EasyOCR if processing many images

## ğŸ§ª Testing

```bash
# Install dev dependencies
pip install pytest pytest-asyncio pytest-cov

# Run tests
pytest tests/ -v --cov=.
```

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

## ğŸ™ Acknowledgments

- [CrewAI](https://github.com/joaomdmoura/crewAI) - Multi-agent framework
- [OpenAI](https://openai.com/) - LLM and embeddings
- [Milvus](https://milvus.io/) / [Zilliz Cloud](https://cloud.zilliz.com) - Vector database
- [EasyOCR](https://github.com/JaidedAI/EasyOCR) - OCR engine
- [spaCy](https://spacy.io/) - NLP processing

---

**Built with â¤ï¸ for Production AI Systems**

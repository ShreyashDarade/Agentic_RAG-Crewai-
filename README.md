# DAY10 - Multi-Agent RAG System

A production-ready, microservices-style Multi-Agent RAG (Retrieval-Augmented Generation) system using CrewAI, Groq, ChromaDB, and FastAPI.

## ğŸ—ï¸ Architecture

```
DAY10/
â”œâ”€â”€ agents/                      # CrewAI-based agent classes
â”‚   â”œâ”€â”€ supervisor_agent.py      # Query planning and tool selection
â”‚   â”œâ”€â”€ retriever_agent.py       # Document and web search
â”‚   â”œâ”€â”€ generator_agent.py       # Answer synthesis
â”‚   â”œâ”€â”€ feedback_agent.py        # Quality assurance
â”‚   â””â”€â”€ tools/                   # Agent tools
â”‚       â”œâ”€â”€ chroma_tool.py       # ChromaDB search
â”‚       â”œâ”€â”€ online_search_tool.py # Web search
â”‚       â””â”€â”€ summarize_tool.py    # Text summarization
â”œâ”€â”€ orchestrator/                # Multi-agent coordination
â”‚   â”œâ”€â”€ crew_manager.py          # Workflow orchestration
â”‚   â”œâ”€â”€ memory_store.py          # Conversation memory
â”‚   â””â”€â”€ trace_logger.py          # Execution tracing
â”œâ”€â”€ llm/                         # LLM abstraction layer
â”‚   â”œâ”€â”€ base_llm.py              # LLM interface
â”‚   â”œâ”€â”€ groq_client.py           # Groq implementation
â”‚   â””â”€â”€ prompt_templates/        # Agent prompts
â”œâ”€â”€ embeddings/                  # Vector embeddings
â”‚   â”œâ”€â”€ embedder.py              # Sentence transformers
â”‚   â”œâ”€â”€ vector_store.py          # ChromaDB wrapper
â”‚   â””â”€â”€ chunk_tags.py            # Chunk tagging
â”œâ”€â”€ retriever/                   # Information retrieval
â”‚   â”œâ”€â”€ chroma_retriever.py      # Local search (BM25 + dense)
â”‚   â”œâ”€â”€ web_retriever.py         # Web search
â”‚   â””â”€â”€ hybrid_retriever.py      # Combined retrieval
â”œâ”€â”€ data_pipeline/               # Document processing
â”‚   â”œâ”€â”€ file_loader.py           # Universal file parsing
â”‚   â”œâ”€â”€ ocr_processor.py         # OCR for images/PDFs
â”‚   â”œâ”€â”€ metadata_filter.py       # Document filtering
â”‚   â”œâ”€â”€ chunker.py               # Text chunking
â”‚   â””â”€â”€ ingestion_pipeline.py    # Full ingestion flow
â”œâ”€â”€ api/                         # FastAPI application
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ query.py             # Query endpoints
â”‚   â”‚   â””â”€â”€ ingest.py            # Ingestion endpoints
â”‚   â”œâ”€â”€ models/                  # Pydantic schemas
â”‚   â””â”€â”€ main.py                  # API entry point
â”œâ”€â”€ config/                      # Configuration
â”‚   â”œâ”€â”€ config.yaml              # Main config
â”‚   â”œâ”€â”€ crew_config.yaml         # Agent config
â”‚   â””â”€â”€ env_example.txt          # Environment template
â”œâ”€â”€ Dockerfile                   # Container definition
â”œâ”€â”€ docker-compose.yml           # Docker composition
â””â”€â”€ requirements.txt             # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker (optional)
- Groq API key

### Installation

1. **Clone and navigate:**
   ```bash
   cd DAY10
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # or
   .\venv\Scripts\activate  # Windows
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment:**
   ```bash
   # Copy and edit the environment template
   cp config/env_example.txt .env
   # Edit .env with your API keys
   ```

5. **Run the API:**
   ```bash
   uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
   ```

### Docker Deployment

```bash
# Build and run
docker-compose up -d

# View logs
docker-compose logs -f api

# Stop
docker-compose down
```

## ğŸ“¡ API Endpoints

### Query Processing

- `POST /api/v1/agent_query` - Process query through multi-agent system
- `POST /api/v1/search` - Direct search without full pipeline
- `GET /api/v1/trace/{trace_id}` - Get execution trace
- `GET /api/v1/history` - Get conversation history

### Document Ingestion

- `POST /api/v1/ingest` - Ingest documents from directory
- `POST /api/v1/ingest/file` - Ingest single file
- `POST /api/v1/ingest/upload` - Upload and ingest file
- `GET /api/v1/ingest/status` - Get ingestion status
- `GET /api/v1/ingest/files` - List ingested files

### Health & Status

- `GET /health` - Health check
- `GET /status` - Detailed status

## ğŸ“– Usage Examples

### Query Example

```bash
curl -X POST "http://localhost:8000/api/v1/agent_query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key features of Python 3.12?",
    "include_sources": true,
    "include_trace": true
  }'
```

### Ingestion Example

```bash
# Ingest from directory
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "directory": "./data/raw",
    "force": false,
    "recursive": true
  }'

# Upload file
curl -X POST "http://localhost:8000/api/v1/ingest/upload" \
  -F "file=@document.pdf"
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GROQ_API_KEY` | Groq API key | Yes |
| `OPENAI_API_KEY` | OpenAI API key (optional) | No |
| `SERPER_API_KEY` | Serper.dev API key (optional) | No |
| `TAVILY_API_KEY` | Tavily API key (optional) | No |
| `APP_ENV` | Environment (development/production) | No |
| `DEBUG` | Enable debug mode | No |
| `LOG_LEVEL` | Logging level | No |

### Config Files

- `config/config.yaml` - Main application configuration
- `config/crew_config.yaml` - Agent and workflow configuration

## ğŸ”§ Features

### Multi-Agent Pipeline

1. **Supervisor Agent** - Analyzes queries, creates execution plans
2. **Retriever Agent** - Searches documents and web
3. **Generator Agent** - Synthesizes answers
4. **Feedback Agent** - Validates and improves responses

### Document Processing

- **Supported Formats:** PDF, DOCX, DOC, TXT, MD, HTML, CSV, XLSX, PPTX, Images
- **OCR:** Automatic OCR for scanned documents
- **Chunking:** Recursive, semantic, and fixed-size strategies
- **Deduplication:** Tracks processed files to avoid reprocessing

### Retrieval

- **Dense Search:** Semantic similarity with sentence-transformers
- **BM25:** Keyword-based retrieval
- **Fuzzy Matching:** Typo-tolerant search
- **Hybrid:** Combines local and web search

### Observability

- **Execution Traces:** Step-by-step tracking
- **Conversation Memory:** Context preservation
- **Health Checks:** Component monitoring

## ğŸ“Š Ingestion State Tracking

The system maintains a JSON file (`data/ingestion_state.json`) to track:

- Processed files and their hashes
- Ingestion timestamps
- Chunk counts
- Processing status

This prevents reprocessing of unchanged files.

## ğŸ”’ Error Handling

- Comprehensive error handling at all levels
- Automatic retries with exponential backoff
- Fallback strategies when agents fail
- Detailed error messages and logging

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

Contributions welcome! Please read the contributing guidelines first.

